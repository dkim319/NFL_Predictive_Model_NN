{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 -  NFL Prediction Model - NN - 2014 to 2018.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMfBt7JD5kZvx1UELYRtAjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkim319/NFL_Predictive_Model_NN/blob/master/2_NFL_Prediction_Model_NN_2014_to_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXj3y7Fjnp9w",
        "colab_type": "text"
      },
      "source": [
        "# NFL Prediction Neural Network Model - 2014 to 2018 (4 Year)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This is a mini-project leverages the data from the previous project that can be viewed here:\n",
        "\n",
        "https://github.com/dkim319/NFL_Predictive_Model_v2\n",
        "\n",
        "The purpose of this mini-project is to build a deep learning model based on the knowledge learned from the Deep Learning and Tensorflow in Practice Specialization courses by DeepLearning.ai.\n",
        "\n",
        "This is the second notebook goes through the same process with using 4 years of NFL data.  The final model in the project references above uses a 4-year training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9CBzK-Jnfcg",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "All required libraries are loaded and the Tensorflow version is checked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TSRC25ZnPyM",
        "colab_type": "code",
        "outputId": "87a4a3fc-b706-4080-ff7c-babdb3fe2a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlSpYYbRpM4o",
        "colab_type": "text"
      },
      "source": [
        "The function to load the data from Github is created, which will do the necessary data transformations and split the data into training, validation, and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsKBMssipMYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(start_year, end_year, val_year):\n",
        "\n",
        "  data = pd.read_csv('https://raw.githubusercontent.com/dkim319/NFL_Predictive_Model_NN/master/Data.csv')\n",
        "\n",
        "  data = data[data['season'] >= start_year]\n",
        "\n",
        "  # replace any null values with 0\n",
        "  data = data.fillna(0)\n",
        "\n",
        "  # use one-hot coding to replace the favorite and underdog categorical variables\n",
        "  fav_team = pd.get_dummies(data['favorite'])\n",
        "  und_team = pd.get_dummies(data['underdog'])\n",
        "\n",
        "  # use a prefix to distinguish the two categorical variables\n",
        "  fav_team = fav_team.add_prefix('fav_')\n",
        "  und_team = und_team.add_prefix('und_')\n",
        "\n",
        "  # remove the original fields\n",
        "  data = data.drop('favorite', axis = 1)\n",
        "  data = data.drop('underdog', axis = 1)\n",
        "\n",
        "  # add the one-hot coded fields\n",
        "  data = pd.concat([data, fav_team], axis = 1)\n",
        "  data = pd.concat([data, und_team], axis = 1)\n",
        "\n",
        "  # split the dataset into training and testing datasets\n",
        "  data_train = data[data['season'] <= end_year-1]\n",
        "  data_train.reset_index()\n",
        "  data_val = data[data['season'] == end_year]\n",
        "  data_val.reset_index()\n",
        "  data_test = data[data['season'] == test_year]\n",
        "  data_test.reset_index()\n",
        "\n",
        "  # split training and testing datasets into features and target \n",
        "  features_train = data_train.drop('spreadflag', axis = 1)\n",
        "  target_train = data_train['spreadflag']\n",
        "\n",
        "  features_val = data_val.drop('spreadflag', axis = 1)\n",
        "  target_val = data_val['spreadflag']\n",
        "\n",
        "  features_test = data_test.drop('spreadflag', axis = 1)\n",
        "  target_test = data_test['spreadflag']\n",
        "\n",
        "  return features_train, target_train, features_val, target_val, features_test, target_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTIGkCgSnwvk",
        "colab_type": "text"
      },
      "source": [
        "## 2. Prep Data for Deep Learning\n",
        "\n",
        "The load_data function is used to get the data and normalize the data in preparation for neural network.  The data is also normalized using a min/max scaler and converted into ndarrays.  This ensure that the data is ready for a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie2PJiF7nxCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_year = 2014\n",
        "end_year = 2018\n",
        "test_year = 2019\n",
        "\n",
        "features_train, target_train, features_val, target_val, features_test, target_test = load_data(start_year, end_year, test_year)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(features_train)\n",
        "\n",
        "x_train = scaler.transform(features_train).astype('float32')\n",
        "x_val = scaler.transform(features_val).astype('float32')\n",
        "x_test = scaler.transform(features_test).astype('float32')\n",
        "\n",
        "y_train = target_train.to_numpy().astype('float32')\n",
        "y_val = target_val.to_numpy().astype('float32')\n",
        "y_test = target_test.to_numpy().astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYavDnw_qsWq",
        "colab_type": "text"
      },
      "source": [
        "Verify the dimensions of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oULewI3gqwMy",
        "colab_type": "code",
        "outputId": "0750d67b-6bb0-413e-e347-884f99e1b5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(988, 252)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbnhDf0Gqx8p",
        "colab_type": "code",
        "outputId": "097a6664-a474-427c-c146-f746acdc6d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(988,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Z6lq1uq4MB",
        "colab_type": "text"
      },
      "source": [
        "Verify the features (x) and target (y) datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkEu6p5xrFCK",
        "colab_type": "code",
        "outputId": "27a2b17a-0c97-4d23-c778-1b940b5e2714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "x_train[:5,:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTEmFlF1rRtk",
        "colab_type": "code",
        "outputId": "8ac8f2cc-b553-43b8-841f-8241baaa0af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIwjprOsrppa",
        "colab_type": "text"
      },
      "source": [
        "## 3. Build the Model\n",
        "\n",
        "The define_model function is created to be able to initialize a model and be able to configure the epochs and learning rate.  The function also allows for the ability to include a learning rate scheduler and/or a model checkpoint as callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIEB13XusMF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(model_number, epoch, learning_rate, lr_cb, cp_cb):\n",
        "\n",
        "  # set the seed and clear session to ensure consistent results and avoid past models impacting the current model\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(319)\n",
        "  np.random.seed(319)\n",
        "  \n",
        "  # initialize the callback list\n",
        "  callback_list = []\n",
        "\n",
        "  if model_number==1:\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(64, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  if model_number==2:\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  if model_number==3:\n",
        "     # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])   \n",
        "\n",
        "  if model_number==4:\n",
        "     # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])  \n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "  if lr_cb==True:\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "        lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "    callback_list.append(lr_schedule)\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=1e-8)\n",
        "\n",
        "  if cp_cb==True:\n",
        "    filepath = str(model_number) + \"_weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "    filedir = os.path.dirname(filepath)\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "\n",
        "  return model, callback_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRkUYxQbt5Tr",
        "colab_type": "text"
      },
      "source": [
        "## 4. Parameter Tuning and Training\n",
        "\n",
        "There are plethora of different parameters to tune, but the possiblities are endless. To keep things simple, the parameter tuned will be the learning rate and network architecture.\n",
        "\n",
        "The baseline (benchmark) for this model will be a naive baseline where the model selects the underdog everytime.  The baseline will be 50.8%.\n",
        "\n",
        "This baseline is referenced in this report:\n",
        "\n",
        "https://github.com/dkim319/NFL_Predictive_Model_v2/blob/master/Report%20-%20David%20Kim%20-%2020190623.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0cg_KH1EMCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chart_acc_loss(model_history):\n",
        "\n",
        "  history = model_history\n",
        "\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaoWYHIXsw_r",
        "colab_type": "code",
        "outputId": "409f10f7-8cf4-43e8-85d3-0aa48571fb13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 1\n",
        "epoch = 160\n",
        "learning_rate = 0.001\n",
        "lr_cb = True\n",
        "cp_cb = False\n",
        "\n",
        "model_lr_sched, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_lr_sched.fit(x_train,y_train, \n",
        "                  epochs=epoch, \n",
        "                  validation_data = (x_val,y_val),\n",
        "                  callbacks=[callback_list])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                16192     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 189,633\n",
            "Trainable params: 189,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/160\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.6991 - accuracy: 0.4889 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.0000e-08\n",
            "Epoch 2/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.1220e-08\n",
            "Epoch 3/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5121 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.2589e-08\n",
            "Epoch 4/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.4727 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.4125e-08\n",
            "Epoch 5/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.5081 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.5849e-08\n",
            "Epoch 6/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.5040 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.7783e-08\n",
            "Epoch 7/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6995 - accuracy: 0.4757 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 1.9953e-08\n",
            "Epoch 8/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.4828 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 2.2387e-08\n",
            "Epoch 9/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5142 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 2.5119e-08\n",
            "Epoch 10/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5051 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 2.8184e-08\n",
            "Epoch 11/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5121 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 3.1623e-08\n",
            "Epoch 12/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5051 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 3.5481e-08\n",
            "Epoch 13/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6986 - accuracy: 0.4767 - val_loss: 0.6972 - val_accuracy: 0.4656 - lr: 3.9811e-08\n",
            "Epoch 14/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6964 - accuracy: 0.4949 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 4.4668e-08\n",
            "Epoch 15/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6969 - accuracy: 0.4949 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 5.0119e-08\n",
            "Epoch 16/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.4990 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 5.6234e-08\n",
            "Epoch 17/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5061 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 6.3096e-08\n",
            "Epoch 18/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 7.0795e-08\n",
            "Epoch 19/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5142 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 7.9433e-08\n",
            "Epoch 20/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5091 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 8.9125e-08\n",
            "Epoch 21/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6989 - accuracy: 0.4838 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 1.0000e-07\n",
            "Epoch 22/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5142 - val_loss: 0.6971 - val_accuracy: 0.4656 - lr: 1.1220e-07\n",
            "Epoch 23/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.4939 - val_loss: 0.6970 - val_accuracy: 0.4656 - lr: 1.2589e-07\n",
            "Epoch 24/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.4889 - val_loss: 0.6970 - val_accuracy: 0.4656 - lr: 1.4125e-07\n",
            "Epoch 25/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5294 - val_loss: 0.6970 - val_accuracy: 0.4656 - lr: 1.5849e-07\n",
            "Epoch 26/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7014 - accuracy: 0.4626 - val_loss: 0.6970 - val_accuracy: 0.4656 - lr: 1.7783e-07\n",
            "Epoch 27/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.5020 - val_loss: 0.6969 - val_accuracy: 0.4696 - lr: 1.9953e-07\n",
            "Epoch 28/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5273 - val_loss: 0.6969 - val_accuracy: 0.4656 - lr: 2.2387e-07\n",
            "Epoch 29/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.4615 - val_loss: 0.6969 - val_accuracy: 0.4656 - lr: 2.5119e-07\n",
            "Epoch 30/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5030 - val_loss: 0.6969 - val_accuracy: 0.4656 - lr: 2.8184e-07\n",
            "Epoch 31/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.5061 - val_loss: 0.6968 - val_accuracy: 0.4656 - lr: 3.1623e-07\n",
            "Epoch 32/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.5294 - val_loss: 0.6968 - val_accuracy: 0.4656 - lr: 3.5481e-07\n",
            "Epoch 33/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.4899 - val_loss: 0.6967 - val_accuracy: 0.4656 - lr: 3.9811e-07\n",
            "Epoch 34/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.4949 - val_loss: 0.6967 - val_accuracy: 0.4656 - lr: 4.4668e-07\n",
            "Epoch 35/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6957 - accuracy: 0.4858 - val_loss: 0.6966 - val_accuracy: 0.4656 - lr: 5.0119e-07\n",
            "Epoch 36/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.4889 - val_loss: 0.6965 - val_accuracy: 0.4696 - lr: 5.6234e-07\n",
            "Epoch 37/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.4949 - val_loss: 0.6965 - val_accuracy: 0.4696 - lr: 6.3096e-07\n",
            "Epoch 38/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6964 - val_accuracy: 0.4696 - lr: 7.0795e-07\n",
            "Epoch 39/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6964 - accuracy: 0.4879 - val_loss: 0.6963 - val_accuracy: 0.4696 - lr: 7.9433e-07\n",
            "Epoch 40/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5051 - val_loss: 0.6962 - val_accuracy: 0.4696 - lr: 8.9125e-07\n",
            "Epoch 41/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.4858 - val_loss: 0.6961 - val_accuracy: 0.4737 - lr: 1.0000e-06\n",
            "Epoch 42/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5071 - val_loss: 0.6959 - val_accuracy: 0.4737 - lr: 1.1220e-06\n",
            "Epoch 43/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6972 - accuracy: 0.4899 - val_loss: 0.6959 - val_accuracy: 0.4737 - lr: 1.2589e-06\n",
            "Epoch 44/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000 - val_loss: 0.6957 - val_accuracy: 0.4818 - lr: 1.4125e-06\n",
            "Epoch 45/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5223 - val_loss: 0.6956 - val_accuracy: 0.4858 - lr: 1.5849e-06\n",
            "Epoch 46/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.4990 - val_loss: 0.6954 - val_accuracy: 0.4777 - lr: 1.7783e-06\n",
            "Epoch 47/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5010 - val_loss: 0.6954 - val_accuracy: 0.4777 - lr: 1.9953e-06\n",
            "Epoch 48/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.4939 - val_loss: 0.6950 - val_accuracy: 0.4615 - lr: 2.2387e-06\n",
            "Epoch 49/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.5040 - val_loss: 0.6948 - val_accuracy: 0.4696 - lr: 2.5119e-06\n",
            "Epoch 50/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.4889 - val_loss: 0.6947 - val_accuracy: 0.4696 - lr: 2.8184e-06\n",
            "Epoch 51/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5223 - val_loss: 0.6944 - val_accuracy: 0.4696 - lr: 3.1623e-06\n",
            "Epoch 52/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.4990 - val_loss: 0.6942 - val_accuracy: 0.4656 - lr: 3.5481e-06\n",
            "Epoch 53/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6939 - val_accuracy: 0.4656 - lr: 3.9811e-06\n",
            "Epoch 54/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.4848 - val_loss: 0.6939 - val_accuracy: 0.4737 - lr: 4.4668e-06\n",
            "Epoch 55/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6968 - accuracy: 0.5020 - val_loss: 0.6938 - val_accuracy: 0.4899 - lr: 5.0119e-06\n",
            "Epoch 56/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5233 - val_loss: 0.6933 - val_accuracy: 0.5101 - lr: 5.6234e-06\n",
            "Epoch 57/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.5364 - val_loss: 0.6932 - val_accuracy: 0.5223 - lr: 6.3096e-06\n",
            "Epoch 58/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.4494 - val_loss: 0.6931 - val_accuracy: 0.5182 - lr: 7.0795e-06\n",
            "Epoch 59/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.4949 - val_loss: 0.6926 - val_accuracy: 0.5101 - lr: 7.9433e-06\n",
            "Epoch 60/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.4828 - val_loss: 0.6926 - val_accuracy: 0.5101 - lr: 8.9125e-06\n",
            "Epoch 61/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6921 - val_accuracy: 0.5061 - lr: 1.0000e-05\n",
            "Epoch 62/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.4868 - val_loss: 0.6924 - val_accuracy: 0.4818 - lr: 1.1220e-05\n",
            "Epoch 63/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5223 - val_loss: 0.6924 - val_accuracy: 0.4777 - lr: 1.2589e-05\n",
            "Epoch 64/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5040 - val_loss: 0.6919 - val_accuracy: 0.5506 - lr: 1.4125e-05\n",
            "Epoch 65/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6918 - accuracy: 0.5334 - val_loss: 0.6928 - val_accuracy: 0.4777 - lr: 1.5849e-05\n",
            "Epoch 66/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.4949 - val_loss: 0.6933 - val_accuracy: 0.4980 - lr: 1.7783e-05\n",
            "Epoch 67/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.4990 - val_loss: 0.6924 - val_accuracy: 0.5020 - lr: 1.9953e-05\n",
            "Epoch 68/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5314 - val_loss: 0.6930 - val_accuracy: 0.4899 - lr: 2.2387e-05\n",
            "Epoch 69/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5071 - val_loss: 0.6932 - val_accuracy: 0.4980 - lr: 2.5119e-05\n",
            "Epoch 70/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.4990 - val_loss: 0.6923 - val_accuracy: 0.5182 - lr: 2.8184e-05\n",
            "Epoch 71/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.5213 - val_loss: 0.6940 - val_accuracy: 0.4737 - lr: 3.1623e-05\n",
            "Epoch 72/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.5294 - val_loss: 0.6940 - val_accuracy: 0.4777 - lr: 3.5481e-05\n",
            "Epoch 73/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5142 - val_loss: 0.6928 - val_accuracy: 0.5142 - lr: 3.9811e-05\n",
            "Epoch 74/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5101 - val_loss: 0.6928 - val_accuracy: 0.4899 - lr: 4.4668e-05\n",
            "Epoch 75/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.4818 - lr: 5.0119e-05\n",
            "Epoch 76/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5243 - val_loss: 0.6951 - val_accuracy: 0.4534 - lr: 5.6234e-05\n",
            "Epoch 77/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.5253 - val_loss: 0.6969 - val_accuracy: 0.4858 - lr: 6.3096e-05\n",
            "Epoch 78/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5182 - val_loss: 0.6954 - val_accuracy: 0.4170 - lr: 7.0795e-05\n",
            "Epoch 79/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5101 - val_loss: 0.6932 - val_accuracy: 0.4980 - lr: 7.9433e-05\n",
            "Epoch 80/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6910 - accuracy: 0.5162 - val_loss: 0.6925 - val_accuracy: 0.5061 - lr: 8.9125e-05\n",
            "Epoch 81/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5172 - val_loss: 0.6978 - val_accuracy: 0.4656 - lr: 1.0000e-04\n",
            "Epoch 82/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.5395 - val_loss: 0.6964 - val_accuracy: 0.4615 - lr: 1.1220e-04\n",
            "Epoch 83/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6910 - accuracy: 0.5061 - val_loss: 0.7015 - val_accuracy: 0.4534 - lr: 1.2589e-04\n",
            "Epoch 84/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.7016 - val_accuracy: 0.4534 - lr: 1.4125e-04\n",
            "Epoch 85/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5577 - val_loss: 0.7058 - val_accuracy: 0.4615 - lr: 1.5849e-04\n",
            "Epoch 86/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5425 - val_loss: 0.6933 - val_accuracy: 0.5425 - lr: 1.7783e-04\n",
            "Epoch 87/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5314 - val_loss: 0.7115 - val_accuracy: 0.4575 - lr: 1.9953e-04\n",
            "Epoch 88/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.5668 - val_loss: 0.7036 - val_accuracy: 0.4534 - lr: 2.2387e-04\n",
            "Epoch 89/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.5739 - val_loss: 0.7093 - val_accuracy: 0.4575 - lr: 2.5119e-04\n",
            "Epoch 90/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.5729 - val_loss: 0.7471 - val_accuracy: 0.4615 - lr: 2.8184e-04\n",
            "Epoch 91/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.5911 - val_loss: 0.7067 - val_accuracy: 0.4939 - lr: 3.1623e-04\n",
            "Epoch 92/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6517 - accuracy: 0.6326 - val_loss: 0.7450 - val_accuracy: 0.4818 - lr: 3.5481e-04\n",
            "Epoch 93/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6215 - val_loss: 0.7687 - val_accuracy: 0.4696 - lr: 3.9811e-04\n",
            "Epoch 94/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6518 - val_loss: 0.7834 - val_accuracy: 0.5061 - lr: 4.4668e-04\n",
            "Epoch 95/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.6700 - val_loss: 0.7728 - val_accuracy: 0.4858 - lr: 5.0119e-04\n",
            "Epoch 96/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.5911 - accuracy: 0.6791 - val_loss: 0.8429 - val_accuracy: 0.4615 - lr: 5.6234e-04\n",
            "Epoch 97/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6050 - accuracy: 0.6711 - val_loss: 0.7760 - val_accuracy: 0.4858 - lr: 6.3096e-04\n",
            "Epoch 98/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.6883 - val_loss: 0.9166 - val_accuracy: 0.4858 - lr: 7.0795e-04\n",
            "Epoch 99/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7429 - val_loss: 0.8569 - val_accuracy: 0.4858 - lr: 7.9433e-04\n",
            "Epoch 100/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7510 - val_loss: 0.9971 - val_accuracy: 0.4737 - lr: 8.9125e-04\n",
            "Epoch 101/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7702 - val_loss: 0.8917 - val_accuracy: 0.4939 - lr: 0.0010\n",
            "Epoch 102/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7794 - val_loss: 1.0144 - val_accuracy: 0.4858 - lr: 0.0011\n",
            "Epoch 103/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7723 - val_loss: 1.1662 - val_accuracy: 0.4534 - lr: 0.0013\n",
            "Epoch 104/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7267 - val_loss: 0.8081 - val_accuracy: 0.4858 - lr: 0.0014\n",
            "Epoch 105/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7682 - val_loss: 1.3441 - val_accuracy: 0.4656 - lr: 0.0016\n",
            "Epoch 106/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7449 - val_loss: 0.9459 - val_accuracy: 0.5020 - lr: 0.0018\n",
            "Epoch 107/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5869 - accuracy: 0.7034 - val_loss: 0.8098 - val_accuracy: 0.5182 - lr: 0.0020\n",
            "Epoch 108/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7470 - val_loss: 0.9738 - val_accuracy: 0.5182 - lr: 0.0022\n",
            "Epoch 109/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7368 - val_loss: 1.1436 - val_accuracy: 0.4939 - lr: 0.0025\n",
            "Epoch 110/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7510 - val_loss: 0.8640 - val_accuracy: 0.4332 - lr: 0.0028\n",
            "Epoch 111/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.6721 - val_loss: 0.8220 - val_accuracy: 0.4737 - lr: 0.0032\n",
            "Epoch 112/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.6761 - val_loss: 1.0318 - val_accuracy: 0.5142 - lr: 0.0035\n",
            "Epoch 113/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.6366 - val_loss: 0.7224 - val_accuracy: 0.4899 - lr: 0.0040\n",
            "Epoch 114/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.5830 - val_loss: 0.6963 - val_accuracy: 0.4737 - lr: 0.0045\n",
            "Epoch 115/160\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6334 - accuracy: 0.5749 - val_loss: 0.7582 - val_accuracy: 0.5101 - lr: 0.0050\n",
            "Epoch 116/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.6012 - val_loss: 0.7638 - val_accuracy: 0.5061 - lr: 0.0056\n",
            "Epoch 117/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.6285 - val_loss: 0.9246 - val_accuracy: 0.5425 - lr: 0.0063\n",
            "Epoch 118/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.6123 - val_loss: 0.7602 - val_accuracy: 0.5830 - lr: 0.0071\n",
            "Epoch 119/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.5870 - val_loss: 0.8743 - val_accuracy: 0.5628 - lr: 0.0079\n",
            "Epoch 120/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6053 - val_loss: 0.7146 - val_accuracy: 0.5101 - lr: 0.0089\n",
            "Epoch 121/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.5172 - val_loss: 0.6904 - val_accuracy: 0.5547 - lr: 0.0100\n",
            "Epoch 122/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5081 - val_loss: 0.6972 - val_accuracy: 0.5385 - lr: 0.0112\n",
            "Epoch 123/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.5142 - val_loss: 0.7605 - val_accuracy: 0.5020 - lr: 0.0126\n",
            "Epoch 124/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.5425 - val_loss: 0.7452 - val_accuracy: 0.5385 - lr: 0.0141\n",
            "Epoch 125/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.5425 - val_loss: 0.7210 - val_accuracy: 0.5425 - lr: 0.0158\n",
            "Epoch 126/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.4970 - val_loss: 0.6909 - val_accuracy: 0.5547 - lr: 0.0178\n",
            "Epoch 127/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.4960 - val_loss: 0.6908 - val_accuracy: 0.5547 - lr: 0.0200\n",
            "Epoch 128/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.4939 - val_loss: 0.6934 - val_accuracy: 0.4453 - lr: 0.0224\n",
            "Epoch 129/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.4767 - val_loss: 0.6922 - val_accuracy: 0.5547 - lr: 0.0251\n",
            "Epoch 130/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.4899 - val_loss: 0.6950 - val_accuracy: 0.4453 - lr: 0.0282\n",
            "Epoch 131/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.5547 - lr: 0.0316\n",
            "Epoch 132/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5061 - val_loss: 0.6912 - val_accuracy: 0.5547 - lr: 0.0355\n",
            "Epoch 133/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.4899 - val_loss: 0.6929 - val_accuracy: 0.5547 - lr: 0.0398\n",
            "Epoch 134/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5061 - val_loss: 0.6933 - val_accuracy: 0.4453 - lr: 0.0447\n",
            "Epoch 135/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6899 - val_accuracy: 0.5547 - lr: 0.0501\n",
            "Epoch 136/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.4960 - val_loss: 0.6960 - val_accuracy: 0.4453 - lr: 0.0562\n",
            "Epoch 137/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.4838 - val_loss: 0.6953 - val_accuracy: 0.4453 - lr: 0.0631\n",
            "Epoch 138/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5061 - val_loss: 0.6899 - val_accuracy: 0.5547 - lr: 0.0708\n",
            "Epoch 139/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.4777 - val_loss: 0.6964 - val_accuracy: 0.4453 - lr: 0.0794\n",
            "Epoch 140/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.4858 - val_loss: 0.6958 - val_accuracy: 0.4453 - lr: 0.0891\n",
            "Epoch 141/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.4818 - val_loss: 0.6919 - val_accuracy: 0.5547 - lr: 0.1000\n",
            "Epoch 142/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.4939 - val_loss: 0.6909 - val_accuracy: 0.5547 - lr: 0.1122\n",
            "Epoch 143/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.4858 - val_loss: 0.6907 - val_accuracy: 0.5547 - lr: 0.1259\n",
            "Epoch 144/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5263 - val_loss: 0.7141 - val_accuracy: 0.4453 - lr: 0.1413\n",
            "Epoch 145/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.5101 - val_loss: 0.6902 - val_accuracy: 0.5547 - lr: 0.1585\n",
            "Epoch 146/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5162 - val_loss: 0.7102 - val_accuracy: 0.4453 - lr: 0.1778\n",
            "Epoch 147/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5061 - val_loss: 0.7003 - val_accuracy: 0.4453 - lr: 0.1995\n",
            "Epoch 148/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6979 - accuracy: 0.5040 - val_loss: 0.7635 - val_accuracy: 0.4453 - lr: 0.2239\n",
            "Epoch 149/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.7022 - accuracy: 0.4919 - val_loss: 0.6898 - val_accuracy: 0.5547 - lr: 0.2512\n",
            "Epoch 150/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7051 - accuracy: 0.4919 - val_loss: 0.7577 - val_accuracy: 0.4453 - lr: 0.2818\n",
            "Epoch 151/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7000 - accuracy: 0.5020 - val_loss: 0.7149 - val_accuracy: 0.4453 - lr: 0.3162\n",
            "Epoch 152/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.4717 - val_loss: 0.6971 - val_accuracy: 0.4453 - lr: 0.3548\n",
            "Epoch 153/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5000 - val_loss: 0.6873 - val_accuracy: 0.5547 - lr: 0.3981\n",
            "Epoch 154/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.4919 - val_loss: 0.6941 - val_accuracy: 0.4453 - lr: 0.4467\n",
            "Epoch 155/160\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.5142 - val_loss: 0.7084 - val_accuracy: 0.4453 - lr: 0.5012\n",
            "Epoch 156/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7006 - accuracy: 0.4939 - val_loss: 0.6925 - val_accuracy: 0.5547 - lr: 0.5623\n",
            "Epoch 157/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.4919 - val_loss: 0.7136 - val_accuracy: 0.4453 - lr: 0.6310\n",
            "Epoch 158/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.5283 - val_loss: 0.7159 - val_accuracy: 0.5547 - lr: 0.7079\n",
            "Epoch 159/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7327 - accuracy: 0.4838 - val_loss: 0.6895 - val_accuracy: 0.5547 - lr: 0.7943\n",
            "Epoch 160/160\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.7084 - accuracy: 0.4939 - val_loss: 0.7027 - val_accuracy: 0.4453 - lr: 0.8913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50W-HNiGueUr",
        "colab_type": "code",
        "outputId": "ecadb79c-43a5-415d-fe2d-9f0bb5aaba84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# review the learning rate performance\n",
        "\n",
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_87QWQfWuloQ",
        "colab_type": "text"
      },
      "source": [
        "Based on the chart, the learning rate of 0.01(10e-3) appears to be the best option, but when a model is trained using this learning rate.  The accuracy and loss charts show instability, which means that the learning rate is probably too high."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuFOKE_Pu_2v",
        "colab_type": "code",
        "outputId": "05ae21d6-1fa0-4301-c051-22d926f4a011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 1\n",
        "epoch = 100\n",
        "learning_rate = 0.01\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "model_lr_sched, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_lr_sched.fit(x_train,y_train, \n",
        "                  epochs=epoch, \n",
        "                  validation_data = (x_val,y_val),\n",
        "                  #callbacks=[callback_list],\n",
        "                  verbose=0)\n",
        "\n",
        "# review the learning rate performance\n",
        "\n",
        "chart_acc_loss(history)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                16192     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 189,633\n",
            "Trainable params: 189,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqYdDtp5FPDE",
        "colab_type": "text"
      },
      "source": [
        "Since the learning rate was too high, the learning rate was adjusted and based on the accuracy/loss charts and validation accuracy.  The learning rate of 0.0001 was selected, which is the same as the 7-year model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CM8BzPAFOXP",
        "colab_type": "code",
        "outputId": "6ff467b3-2f24-4dd9-c10f-df6ce8bdd2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 1\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "model_lr, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_lr.fit(x_train,y_train, \n",
        "                  epochs=epoch, \n",
        "                  validation_data = (x_val,y_val),\n",
        "                  #callbacks=[callback_list],\n",
        "                  verbose=0)\n",
        "\n",
        "# review the learning rate performance\n",
        "\n",
        "chart_acc_loss(history)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                16192     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 189,633\n",
            "Trainable params: 189,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpcRzoCVueFl",
        "colab_type": "text"
      },
      "source": [
        "## Training and Tuning the Archictecture\n",
        "\n",
        "There was not an efficient way to adjust the architecture (model layers), so multiple variations were tested.  The training accuracy, validation accuracy, and epochs were used to evaluate which model to select.  Checkpoint callback was used to save the weights from the epoch with the highest validation accuracy.\n",
        "\n",
        "Since this step can be endless as there are an infinite number of layer combinations, three were selected.  The models selected had the highest validation accuracy and had a higher training accuracy than validation accuracy.  This meant that the models were overfitted, but an overfitted model is better than an underfitted model.  Also, the model selected reached their best validation accuracy after 5 epochs, which ensured that enough training occurred.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrlP0cgvSI0l",
        "colab_type": "text"
      },
      "source": [
        "Model #2 Architecture:\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "* Epoch - 19\n",
        "* Training Accuracy - 0.5898\n",
        "* Validation Accuracy - 0.56275\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XvEVKsLxmOM",
        "colab_type": "code",
        "outputId": "08a892b4-65be-4a46-80ff-586c41455830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 2\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = True\n",
        "\n",
        "model_2, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_2.fit(x_train,y_train, \n",
        "                  epochs=epoch, \n",
        "                  validation_data = (x_val,y_val),\n",
        "                  callbacks=[callback_list])\n",
        "\n",
        "# review the learning rate performance\n",
        "chart_acc_loss(history)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.7019 - accuracy: 0.4823\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.53441, saving model to 2_weights-improvement-01-0.53.hdf5\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7001 - accuracy: 0.4929 - val_loss: 0.6947 - val_accuracy: 0.5344\n",
            "Epoch 2/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6950 - accuracy: 0.5258\n",
            "Epoch 00002: val_accuracy did not improve from 0.53441\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5304 - val_loss: 0.6932 - val_accuracy: 0.5101\n",
            "Epoch 3/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6951 - accuracy: 0.5125\n",
            "Epoch 00003: val_accuracy did not improve from 0.53441\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5051 - val_loss: 0.6937 - val_accuracy: 0.5020\n",
            "Epoch 4/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.6909 - accuracy: 0.5327\n",
            "Epoch 00004: val_accuracy did not improve from 0.53441\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.5354 - val_loss: 0.6923 - val_accuracy: 0.5223\n",
            "Epoch 5/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6878 - accuracy: 0.5516\n",
            "Epoch 00005: val_accuracy did not improve from 0.53441\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5334 - val_loss: 0.6922 - val_accuracy: 0.5304\n",
            "Epoch 6/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.6901 - accuracy: 0.5511\n",
            "Epoch 00006: val_accuracy did not improve from 0.53441\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5557 - val_loss: 0.6933 - val_accuracy: 0.5223\n",
            "Epoch 7/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6930 - accuracy: 0.5299\n",
            "Epoch 00007: val_accuracy improved from 0.53441 to 0.55466, saving model to 2_weights-improvement-07-0.55.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5273 - val_loss: 0.6926 - val_accuracy: 0.5547\n",
            "Epoch 8/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6920 - accuracy: 0.5221\n",
            "Epoch 00008: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5202 - val_loss: 0.6941 - val_accuracy: 0.5061\n",
            "Epoch 9/100\n",
            "20/31 [==================>...........] - ETA: 0s - loss: 0.6816 - accuracy: 0.5547\n",
            "Epoch 00009: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5526 - val_loss: 0.6944 - val_accuracy: 0.4939\n",
            "Epoch 10/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6838 - accuracy: 0.5525\n",
            "Epoch 00010: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5425 - val_loss: 0.6931 - val_accuracy: 0.5344\n",
            "Epoch 11/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6865 - accuracy: 0.5611\n",
            "Epoch 00011: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5557 - val_loss: 0.6932 - val_accuracy: 0.5547\n",
            "Epoch 12/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6819 - accuracy: 0.5850\n",
            "Epoch 00012: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5739 - val_loss: 0.6914 - val_accuracy: 0.5466\n",
            "Epoch 13/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6848 - accuracy: 0.5508\n",
            "Epoch 00013: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5577 - val_loss: 0.6930 - val_accuracy: 0.5344\n",
            "Epoch 14/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6790 - accuracy: 0.5677\n",
            "Epoch 00014: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5678 - val_loss: 0.6943 - val_accuracy: 0.5506\n",
            "Epoch 15/100\n",
            "20/31 [==================>...........] - ETA: 0s - loss: 0.6827 - accuracy: 0.5594\n",
            "Epoch 00015: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.5638 - val_loss: 0.6989 - val_accuracy: 0.5020\n",
            "Epoch 16/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6813 - accuracy: 0.5547\n",
            "Epoch 00016: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5628 - val_loss: 0.6932 - val_accuracy: 0.5304\n",
            "Epoch 17/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6735 - accuracy: 0.5747\n",
            "Epoch 00017: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5769 - val_loss: 0.6939 - val_accuracy: 0.5263\n",
            "Epoch 18/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6737 - accuracy: 0.5807\n",
            "Epoch 00018: val_accuracy did not improve from 0.55466\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5749 - val_loss: 0.6931 - val_accuracy: 0.5223\n",
            "Epoch 19/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6687 - accuracy: 0.5913\n",
            "Epoch 00019: val_accuracy improved from 0.55466 to 0.56275, saving model to 2_weights-improvement-19-0.56.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.5860 - val_loss: 0.6970 - val_accuracy: 0.5628\n",
            "Epoch 20/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6685 - accuracy: 0.5978\n",
            "Epoch 00020: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6032 - val_loss: 0.7005 - val_accuracy: 0.5182\n",
            "Epoch 21/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6628 - accuracy: 0.6081\n",
            "Epoch 00021: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6113 - val_loss: 0.6969 - val_accuracy: 0.5304\n",
            "Epoch 22/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6493 - accuracy: 0.6440\n",
            "Epoch 00022: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.6346 - val_loss: 0.7042 - val_accuracy: 0.5304\n",
            "Epoch 23/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6571 - accuracy: 0.6068\n",
            "Epoch 00023: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5982 - val_loss: 0.6990 - val_accuracy: 0.5182\n",
            "Epoch 24/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6510 - accuracy: 0.6209\n",
            "Epoch 00024: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6134 - val_loss: 0.7045 - val_accuracy: 0.5223\n",
            "Epoch 25/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6483 - accuracy: 0.6276\n",
            "Epoch 00025: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6235 - val_loss: 0.7095 - val_accuracy: 0.5182\n",
            "Epoch 26/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6419 - accuracy: 0.6393\n",
            "Epoch 00026: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6346 - val_loss: 0.7186 - val_accuracy: 0.5061\n",
            "Epoch 27/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6403 - accuracy: 0.6471\n",
            "Epoch 00027: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6387 - val_loss: 0.7081 - val_accuracy: 0.5223\n",
            "Epoch 28/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6367 - accuracy: 0.6350\n",
            "Epoch 00028: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6225 - val_loss: 0.7113 - val_accuracy: 0.5344\n",
            "Epoch 29/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6312 - accuracy: 0.6576\n",
            "Epoch 00029: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6640 - val_loss: 0.7153 - val_accuracy: 0.5344\n",
            "Epoch 30/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6280 - accuracy: 0.6475\n",
            "Epoch 00030: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6457 - val_loss: 0.7196 - val_accuracy: 0.5385\n",
            "Epoch 31/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.6269 - accuracy: 0.6562\n",
            "Epoch 00031: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6549 - val_loss: 0.7189 - val_accuracy: 0.5304\n",
            "Epoch 32/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6148 - accuracy: 0.6750\n",
            "Epoch 00032: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6619 - val_loss: 0.7421 - val_accuracy: 0.4899\n",
            "Epoch 33/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6070 - accuracy: 0.6750\n",
            "Epoch 00033: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6711 - val_loss: 0.7360 - val_accuracy: 0.5142\n",
            "Epoch 34/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6167 - accuracy: 0.6706\n",
            "Epoch 00034: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6690 - val_loss: 0.7472 - val_accuracy: 0.5101\n",
            "Epoch 35/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5987 - accuracy: 0.6837\n",
            "Epoch 00035: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6903 - val_loss: 0.7461 - val_accuracy: 0.5061\n",
            "Epoch 36/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5967 - accuracy: 0.7024\n",
            "Epoch 00036: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6913 - val_loss: 0.7388 - val_accuracy: 0.5223\n",
            "Epoch 37/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6114 - accuracy: 0.6471\n",
            "Epoch 00037: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6609 - val_loss: 0.7391 - val_accuracy: 0.5142\n",
            "Epoch 38/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.5925 - accuracy: 0.6960\n",
            "Epoch 00038: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.6872 - val_loss: 0.7420 - val_accuracy: 0.5020\n",
            "Epoch 39/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5758 - accuracy: 0.7038\n",
            "Epoch 00039: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7075 - val_loss: 0.7503 - val_accuracy: 0.5182\n",
            "Epoch 40/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5764 - accuracy: 0.7000\n",
            "Epoch 00040: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7034 - val_loss: 0.7606 - val_accuracy: 0.5263\n",
            "Epoch 41/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5647 - accuracy: 0.6988\n",
            "Epoch 00041: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7085 - val_loss: 0.7838 - val_accuracy: 0.5061\n",
            "Epoch 42/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5608 - accuracy: 0.7063\n",
            "Epoch 00042: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7105 - val_loss: 0.7847 - val_accuracy: 0.5061\n",
            "Epoch 43/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5624 - accuracy: 0.7013\n",
            "Epoch 00043: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7075 - val_loss: 0.8033 - val_accuracy: 0.4939\n",
            "Epoch 44/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5500 - accuracy: 0.7337\n",
            "Epoch 00044: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7247 - val_loss: 0.8077 - val_accuracy: 0.4818\n",
            "Epoch 45/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5472 - accuracy: 0.7287\n",
            "Epoch 00045: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7298 - val_loss: 0.8176 - val_accuracy: 0.4818\n",
            "Epoch 46/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5424 - accuracy: 0.7351\n",
            "Epoch 00046: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7358 - val_loss: 0.8136 - val_accuracy: 0.4899\n",
            "Epoch 47/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5126 - accuracy: 0.7669\n",
            "Epoch 00047: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7672 - val_loss: 0.7893 - val_accuracy: 0.5344\n",
            "Epoch 48/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5127 - accuracy: 0.7525\n",
            "Epoch 00048: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7591 - val_loss: 0.8302 - val_accuracy: 0.4939\n",
            "Epoch 49/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5110 - accuracy: 0.7604\n",
            "Epoch 00049: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7591 - val_loss: 0.8561 - val_accuracy: 0.4858\n",
            "Epoch 50/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.4788 - accuracy: 0.7930\n",
            "Epoch 00050: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7874 - val_loss: 0.8387 - val_accuracy: 0.4899\n",
            "Epoch 51/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4638 - accuracy: 0.7987\n",
            "Epoch 00051: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7966 - val_loss: 0.8632 - val_accuracy: 0.4899\n",
            "Epoch 52/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4807 - accuracy: 0.7745\n",
            "Epoch 00052: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7753 - val_loss: 0.8881 - val_accuracy: 0.4980\n",
            "Epoch 53/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4776 - accuracy: 0.7745\n",
            "Epoch 00053: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7794 - val_loss: 0.8741 - val_accuracy: 0.4980\n",
            "Epoch 54/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4475 - accuracy: 0.8000\n",
            "Epoch 00054: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8026 - val_loss: 0.8555 - val_accuracy: 0.5101\n",
            "Epoch 55/100\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.4500 - accuracy: 0.8006\n",
            "Epoch 00055: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.8067 - val_loss: 0.8826 - val_accuracy: 0.5142\n",
            "Epoch 56/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4370 - accuracy: 0.7989\n",
            "Epoch 00056: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8047 - val_loss: 0.9460 - val_accuracy: 0.4858\n",
            "Epoch 57/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.4180 - accuracy: 0.8255\n",
            "Epoch 00057: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8188 - val_loss: 0.9354 - val_accuracy: 0.5101\n",
            "Epoch 58/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4128 - accuracy: 0.8261\n",
            "Epoch 00058: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8279 - val_loss: 0.9432 - val_accuracy: 0.5061\n",
            "Epoch 59/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4049 - accuracy: 0.8313\n",
            "Epoch 00059: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8310 - val_loss: 0.9634 - val_accuracy: 0.5101\n",
            "Epoch 60/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.3942 - accuracy: 0.8397\n",
            "Epoch 00060: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8370 - val_loss: 0.9735 - val_accuracy: 0.5061\n",
            "Epoch 61/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3806 - accuracy: 0.8475\n",
            "Epoch 00061: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8350 - val_loss: 1.0241 - val_accuracy: 0.4818\n",
            "Epoch 62/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.3921 - accuracy: 0.8424\n",
            "Epoch 00062: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8421 - val_loss: 1.0004 - val_accuracy: 0.5061\n",
            "Epoch 63/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3756 - accuracy: 0.8450\n",
            "Epoch 00063: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8431 - val_loss: 0.9679 - val_accuracy: 0.5223\n",
            "Epoch 64/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3580 - accuracy: 0.8550\n",
            "Epoch 00064: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8532 - val_loss: 1.0413 - val_accuracy: 0.5061\n",
            "Epoch 65/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.3796 - accuracy: 0.8320\n",
            "Epoch 00065: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8421 - val_loss: 1.0157 - val_accuracy: 0.5182\n",
            "Epoch 66/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.3256 - accuracy: 0.8724\n",
            "Epoch 00066: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8725 - val_loss: 0.9974 - val_accuracy: 0.5142\n",
            "Epoch 67/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.3286 - accuracy: 0.8622\n",
            "Epoch 00067: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8583 - val_loss: 1.0437 - val_accuracy: 0.5263\n",
            "Epoch 68/100\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.3394 - accuracy: 0.8676\n",
            "Epoch 00068: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8674 - val_loss: 1.0592 - val_accuracy: 0.5142\n",
            "Epoch 69/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2983 - accuracy: 0.8938\n",
            "Epoch 00069: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8816 - val_loss: 1.0393 - val_accuracy: 0.5142\n",
            "Epoch 70/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2788 - accuracy: 0.8988\n",
            "Epoch 00070: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8988 - val_loss: 1.1797 - val_accuracy: 0.4899\n",
            "Epoch 71/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.2828 - accuracy: 0.8918\n",
            "Epoch 00071: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8866 - val_loss: 1.0873 - val_accuracy: 0.5142\n",
            "Epoch 72/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2857 - accuracy: 0.8938\n",
            "Epoch 00072: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.8897 - val_loss: 1.1661 - val_accuracy: 0.5101\n",
            "Epoch 73/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2621 - accuracy: 0.9050\n",
            "Epoch 00073: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.9028 - val_loss: 1.1505 - val_accuracy: 0.5263\n",
            "Epoch 74/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.2296 - accuracy: 0.9171\n",
            "Epoch 00074: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.8998 - val_loss: 1.1507 - val_accuracy: 0.5344\n",
            "Epoch 75/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2505 - accuracy: 0.9010\n",
            "Epoch 00075: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9028 - val_loss: 1.2118 - val_accuracy: 0.5263\n",
            "Epoch 76/100\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.2577 - accuracy: 0.9018\n",
            "Epoch 00076: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9028 - val_loss: 1.1964 - val_accuracy: 0.5344\n",
            "Epoch 77/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.2319 - accuracy: 0.9239\n",
            "Epoch 00077: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.9200 - val_loss: 1.2125 - val_accuracy: 0.5263\n",
            "Epoch 78/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2304 - accuracy: 0.9219\n",
            "Epoch 00078: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9150 - val_loss: 1.1889 - val_accuracy: 0.5223\n",
            "Epoch 79/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.2394 - accuracy: 0.9130\n",
            "Epoch 00079: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9099 - val_loss: 1.2898 - val_accuracy: 0.5223\n",
            "Epoch 80/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2142 - accuracy: 0.9312\n",
            "Epoch 00080: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2127 - accuracy: 0.9312 - val_loss: 1.2858 - val_accuracy: 0.5182\n",
            "Epoch 81/100\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.2284 - accuracy: 0.9211\n",
            "Epoch 00081: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9221 - val_loss: 1.2850 - val_accuracy: 0.5142\n",
            "Epoch 82/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2272 - accuracy: 0.9087\n",
            "Epoch 00082: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9109 - val_loss: 1.3260 - val_accuracy: 0.5223\n",
            "Epoch 83/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.2239 - accuracy: 0.9134\n",
            "Epoch 00083: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9211 - val_loss: 1.2651 - val_accuracy: 0.5142\n",
            "Epoch 84/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.1924 - accuracy: 0.9362\n",
            "Epoch 00084: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.9362 - val_loss: 1.3291 - val_accuracy: 0.5304\n",
            "Epoch 85/100\n",
            "19/31 [=================>............] - ETA: 0s - loss: 0.1951 - accuracy: 0.9178\n",
            "Epoch 00085: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9221 - val_loss: 1.3528 - val_accuracy: 0.5344\n",
            "Epoch 86/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.1852 - accuracy: 0.9362\n",
            "Epoch 00086: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9372 - val_loss: 1.3191 - val_accuracy: 0.5263\n",
            "Epoch 87/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1710 - accuracy: 0.9413\n",
            "Epoch 00087: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9322 - val_loss: 1.3680 - val_accuracy: 0.5263\n",
            "Epoch 88/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1824 - accuracy: 0.9300\n",
            "Epoch 00088: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9251 - val_loss: 1.3758 - val_accuracy: 0.5344\n",
            "Epoch 89/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.1696 - accuracy: 0.9402\n",
            "Epoch 00089: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9433 - val_loss: 1.3479 - val_accuracy: 0.5223\n",
            "Epoch 90/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1823 - accuracy: 0.9275\n",
            "Epoch 00090: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9332 - val_loss: 1.4048 - val_accuracy: 0.5223\n",
            "Epoch 91/100\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.1745 - accuracy: 0.9345\n",
            "Epoch 00091: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9342 - val_loss: 1.4130 - val_accuracy: 0.5344\n",
            "Epoch 92/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.1716 - accuracy: 0.9457\n",
            "Epoch 00092: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9474 - val_loss: 1.4099 - val_accuracy: 0.5182\n",
            "Epoch 93/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.1763 - accuracy: 0.9388\n",
            "Epoch 00093: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9433 - val_loss: 1.4333 - val_accuracy: 0.5344\n",
            "Epoch 94/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.1576 - accuracy: 0.9403\n",
            "Epoch 00094: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9484 - val_loss: 1.4242 - val_accuracy: 0.5182\n",
            "Epoch 95/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1633 - accuracy: 0.9425\n",
            "Epoch 00095: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9433 - val_loss: 1.5044 - val_accuracy: 0.5304\n",
            "Epoch 96/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.1336 - accuracy: 0.9470\n",
            "Epoch 00096: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9534 - val_loss: 1.4734 - val_accuracy: 0.5142\n",
            "Epoch 97/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1331 - accuracy: 0.9513\n",
            "Epoch 00097: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9575 - val_loss: 1.5005 - val_accuracy: 0.5182\n",
            "Epoch 98/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.1413 - accuracy: 0.9518\n",
            "Epoch 00098: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9504 - val_loss: 1.5607 - val_accuracy: 0.5223\n",
            "Epoch 99/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1602 - accuracy: 0.9425\n",
            "Epoch 00099: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9413 - val_loss: 1.4985 - val_accuracy: 0.5223\n",
            "Epoch 100/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.1403 - accuracy: 0.9466\n",
            "Epoch 00100: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9474 - val_loss: 1.5576 - val_accuracy: 0.5142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5iebq6IQKce",
        "colab_type": "text"
      },
      "source": [
        "Model #3 Architecture:\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])   \n",
        "\n",
        "* Epoch - 77\n",
        "* Training Accuracy - 0.8570\n",
        "* Validation Accuracy - 0.56275"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwaxarsnvOXr",
        "colab_type": "code",
        "outputId": "2c5ad9ec-7582-4ebe-8278-008401a63cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 3\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = True\n",
        "\n",
        "model_3, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_3.fit(x_train,y_train, \n",
        "                  epochs=epoch, \n",
        "                  validation_data = (x_val,y_val),\n",
        "                  callbacks=[callback_list])\n",
        "\n",
        "# review the learning rate performance\n",
        "chart_acc_loss(history)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 49,025\n",
            "Trainable params: 49,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.7055 - accuracy: 0.5120\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.51822, saving model to 3_weights-improvement-01-0.52.hdf5\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.7047 - accuracy: 0.5132 - val_loss: 0.6950 - val_accuracy: 0.5182\n",
            "Epoch 2/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6986 - accuracy: 0.5088\n",
            "Epoch 00002: val_accuracy improved from 0.51822 to 0.53036, saving model to 3_weights-improvement-02-0.53.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.5132 - val_loss: 0.6914 - val_accuracy: 0.5304\n",
            "Epoch 3/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.7045 - accuracy: 0.4821\n",
            "Epoch 00003: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.4848 - val_loss: 0.6920 - val_accuracy: 0.5101\n",
            "Epoch 4/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6918 - accuracy: 0.5174\n",
            "Epoch 00004: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5182 - val_loss: 0.6900 - val_accuracy: 0.5304\n",
            "Epoch 5/100\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.6947 - accuracy: 0.4946\n",
            "Epoch 00005: val_accuracy improved from 0.53036 to 0.55061, saving model to 3_weights-improvement-05-0.55.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.4949 - val_loss: 0.6900 - val_accuracy: 0.5506\n",
            "Epoch 6/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6895 - accuracy: 0.5255\n",
            "Epoch 00006: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5294 - val_loss: 0.6926 - val_accuracy: 0.4899\n",
            "Epoch 7/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6841 - accuracy: 0.5601\n",
            "Epoch 00007: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5597 - val_loss: 0.6925 - val_accuracy: 0.4980\n",
            "Epoch 8/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6833 - accuracy: 0.5368\n",
            "Epoch 00008: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5334 - val_loss: 0.6962 - val_accuracy: 0.4615\n",
            "Epoch 9/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6809 - accuracy: 0.5775\n",
            "Epoch 00009: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.5759 - val_loss: 0.6922 - val_accuracy: 0.4939\n",
            "Epoch 10/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6833 - accuracy: 0.5647\n",
            "Epoch 00010: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5678 - val_loss: 0.6923 - val_accuracy: 0.5020\n",
            "Epoch 11/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6780 - accuracy: 0.5475\n",
            "Epoch 00011: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5516 - val_loss: 0.6928 - val_accuracy: 0.5061\n",
            "Epoch 12/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6746 - accuracy: 0.5856\n",
            "Epoch 00012: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5870 - val_loss: 0.6909 - val_accuracy: 0.5223\n",
            "Epoch 13/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6768 - accuracy: 0.5826\n",
            "Epoch 00013: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5789 - val_loss: 0.6931 - val_accuracy: 0.5344\n",
            "Epoch 14/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6720 - accuracy: 0.6010\n",
            "Epoch 00014: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5992 - val_loss: 0.6937 - val_accuracy: 0.5223\n",
            "Epoch 15/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6775 - accuracy: 0.5792\n",
            "Epoch 00015: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5840 - val_loss: 0.6989 - val_accuracy: 0.4980\n",
            "Epoch 16/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6675 - accuracy: 0.5974\n",
            "Epoch 00016: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.5962 - val_loss: 0.6940 - val_accuracy: 0.5344\n",
            "Epoch 17/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6692 - accuracy: 0.5868\n",
            "Epoch 00017: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5800 - val_loss: 0.6940 - val_accuracy: 0.5385\n",
            "Epoch 18/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6689 - accuracy: 0.6034\n",
            "Epoch 00018: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6012 - val_loss: 0.6959 - val_accuracy: 0.5223\n",
            "Epoch 19/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6609 - accuracy: 0.6172\n",
            "Epoch 00019: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6063 - val_loss: 0.6985 - val_accuracy: 0.5182\n",
            "Epoch 20/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6648 - accuracy: 0.5990\n",
            "Epoch 00020: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6012 - val_loss: 0.7008 - val_accuracy: 0.5223\n",
            "Epoch 21/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6607 - accuracy: 0.6134\n",
            "Epoch 00021: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6134 - val_loss: 0.6972 - val_accuracy: 0.5425\n",
            "Epoch 22/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6561 - accuracy: 0.6227\n",
            "Epoch 00022: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6265 - val_loss: 0.7025 - val_accuracy: 0.5182\n",
            "Epoch 23/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6564 - accuracy: 0.6088\n",
            "Epoch 00023: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6144 - val_loss: 0.6985 - val_accuracy: 0.5385\n",
            "Epoch 24/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6512 - accuracy: 0.6272\n",
            "Epoch 00024: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6346 - val_loss: 0.7022 - val_accuracy: 0.5344\n",
            "Epoch 25/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6490 - accuracy: 0.6389\n",
            "Epoch 00025: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6366 - val_loss: 0.7047 - val_accuracy: 0.5385\n",
            "Epoch 26/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.6407 - accuracy: 0.6400\n",
            "Epoch 00026: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6346 - val_loss: 0.7130 - val_accuracy: 0.5142\n",
            "Epoch 27/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6467 - accuracy: 0.6430\n",
            "Epoch 00027: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6346 - val_loss: 0.7019 - val_accuracy: 0.5385\n",
            "Epoch 28/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6376 - accuracy: 0.6473\n",
            "Epoch 00028: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6447 - val_loss: 0.7015 - val_accuracy: 0.5466\n",
            "Epoch 29/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6433 - accuracy: 0.6445\n",
            "Epoch 00029: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6508 - val_loss: 0.7060 - val_accuracy: 0.5506\n",
            "Epoch 30/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6253 - accuracy: 0.6763\n",
            "Epoch 00030: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6700 - val_loss: 0.7119 - val_accuracy: 0.5344\n",
            "Epoch 31/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6284 - accuracy: 0.6812\n",
            "Epoch 00031: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6893 - val_loss: 0.7062 - val_accuracy: 0.5466\n",
            "Epoch 32/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6289 - accuracy: 0.6775\n",
            "Epoch 00032: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6771 - val_loss: 0.7147 - val_accuracy: 0.5182\n",
            "Epoch 33/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6244 - accuracy: 0.6750\n",
            "Epoch 00033: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6700 - val_loss: 0.7120 - val_accuracy: 0.5385\n",
            "Epoch 34/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6240 - accuracy: 0.6763\n",
            "Epoch 00034: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6700 - val_loss: 0.7232 - val_accuracy: 0.5101\n",
            "Epoch 35/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6259 - accuracy: 0.6526\n",
            "Epoch 00035: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6559 - val_loss: 0.7143 - val_accuracy: 0.5263\n",
            "Epoch 36/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.6155 - accuracy: 0.6953\n",
            "Epoch 00036: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6913 - val_loss: 0.7215 - val_accuracy: 0.5263\n",
            "Epoch 37/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6204 - accuracy: 0.6791\n",
            "Epoch 00037: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6883 - val_loss: 0.7144 - val_accuracy: 0.5385\n",
            "Epoch 38/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6160 - accuracy: 0.6647\n",
            "Epoch 00038: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6660 - val_loss: 0.7155 - val_accuracy: 0.5466\n",
            "Epoch 39/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5934 - accuracy: 0.7095\n",
            "Epoch 00039: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7166 - val_loss: 0.7163 - val_accuracy: 0.5344\n",
            "Epoch 40/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5842 - accuracy: 0.7076\n",
            "Epoch 00040: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7075 - val_loss: 0.7244 - val_accuracy: 0.5263\n",
            "Epoch 41/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5964 - accuracy: 0.7031\n",
            "Epoch 00041: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6984 - val_loss: 0.7330 - val_accuracy: 0.5223\n",
            "Epoch 42/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5948 - accuracy: 0.7095\n",
            "Epoch 00042: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7055 - val_loss: 0.7309 - val_accuracy: 0.5142\n",
            "Epoch 43/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5910 - accuracy: 0.7050\n",
            "Epoch 00043: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7045 - val_loss: 0.7325 - val_accuracy: 0.5223\n",
            "Epoch 44/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5882 - accuracy: 0.6953\n",
            "Epoch 00044: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6943 - val_loss: 0.7474 - val_accuracy: 0.5020\n",
            "Epoch 45/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5696 - accuracy: 0.7257\n",
            "Epoch 00045: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7267 - val_loss: 0.7540 - val_accuracy: 0.5101\n",
            "Epoch 46/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5790 - accuracy: 0.7245\n",
            "Epoch 00046: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7247 - val_loss: 0.7449 - val_accuracy: 0.5101\n",
            "Epoch 47/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5586 - accuracy: 0.7292\n",
            "Epoch 00047: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7247 - val_loss: 0.7303 - val_accuracy: 0.5385\n",
            "Epoch 48/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5706 - accuracy: 0.7254\n",
            "Epoch 00048: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7257 - val_loss: 0.7705 - val_accuracy: 0.4939\n",
            "Epoch 49/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.5670 - accuracy: 0.7332\n",
            "Epoch 00049: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7348 - val_loss: 0.7654 - val_accuracy: 0.5061\n",
            "Epoch 50/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5457 - accuracy: 0.7567\n",
            "Epoch 00050: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7540 - val_loss: 0.7584 - val_accuracy: 0.5061\n",
            "Epoch 51/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5520 - accuracy: 0.7442\n",
            "Epoch 00051: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7439 - val_loss: 0.7594 - val_accuracy: 0.5020\n",
            "Epoch 52/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5507 - accuracy: 0.7299\n",
            "Epoch 00052: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7409 - val_loss: 0.7684 - val_accuracy: 0.5061\n",
            "Epoch 53/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.5447 - accuracy: 0.7428\n",
            "Epoch 00053: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7429 - val_loss: 0.7569 - val_accuracy: 0.5182\n",
            "Epoch 54/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5332 - accuracy: 0.7612\n",
            "Epoch 00054: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7601 - val_loss: 0.7516 - val_accuracy: 0.5466\n",
            "Epoch 55/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5202 - accuracy: 0.7734\n",
            "Epoch 00055: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7682 - val_loss: 0.7594 - val_accuracy: 0.5466\n",
            "Epoch 56/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5240 - accuracy: 0.7712\n",
            "Epoch 00056: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7804 - val_loss: 0.7904 - val_accuracy: 0.5142\n",
            "Epoch 57/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.5106 - accuracy: 0.7701\n",
            "Epoch 00057: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7713 - val_loss: 0.7826 - val_accuracy: 0.5182\n",
            "Epoch 58/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.5138 - accuracy: 0.7885\n",
            "Epoch 00058: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7854 - val_loss: 0.7795 - val_accuracy: 0.5263\n",
            "Epoch 59/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.5055 - accuracy: 0.7859\n",
            "Epoch 00059: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7874 - val_loss: 0.8018 - val_accuracy: 0.5020\n",
            "Epoch 60/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5015 - accuracy: 0.7812\n",
            "Epoch 00060: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7834 - val_loss: 0.7871 - val_accuracy: 0.5304\n",
            "Epoch 61/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4978 - accuracy: 0.7801\n",
            "Epoch 00061: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7834 - val_loss: 0.8030 - val_accuracy: 0.5101\n",
            "Epoch 62/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4880 - accuracy: 0.7980\n",
            "Epoch 00062: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7986 - val_loss: 0.8029 - val_accuracy: 0.5061\n",
            "Epoch 63/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4861 - accuracy: 0.7946\n",
            "Epoch 00063: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7996 - val_loss: 0.8122 - val_accuracy: 0.5142\n",
            "Epoch 64/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4655 - accuracy: 0.7991\n",
            "Epoch 00064: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8036 - val_loss: 0.8492 - val_accuracy: 0.4939\n",
            "Epoch 65/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4890 - accuracy: 0.7656\n",
            "Epoch 00065: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7733 - val_loss: 0.8149 - val_accuracy: 0.5385\n",
            "Epoch 66/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4520 - accuracy: 0.8229\n",
            "Epoch 00066: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8219 - val_loss: 0.8062 - val_accuracy: 0.5466\n",
            "Epoch 67/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4537 - accuracy: 0.8229\n",
            "Epoch 00067: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8209 - val_loss: 0.8240 - val_accuracy: 0.5425\n",
            "Epoch 68/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4489 - accuracy: 0.8090\n",
            "Epoch 00068: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8107 - val_loss: 0.8439 - val_accuracy: 0.5061\n",
            "Epoch 69/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4220 - accuracy: 0.8363\n",
            "Epoch 00069: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8310 - val_loss: 0.8404 - val_accuracy: 0.5223\n",
            "Epoch 70/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.4271 - accuracy: 0.8529\n",
            "Epoch 00070: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8401 - val_loss: 0.8871 - val_accuracy: 0.5061\n",
            "Epoch 71/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4296 - accuracy: 0.8299\n",
            "Epoch 00071: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8239 - val_loss: 0.8411 - val_accuracy: 0.5506\n",
            "Epoch 72/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4181 - accuracy: 0.8426\n",
            "Epoch 00072: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8381 - val_loss: 0.8631 - val_accuracy: 0.5223\n",
            "Epoch 73/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4102 - accuracy: 0.8471\n",
            "Epoch 00073: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8472 - val_loss: 0.8665 - val_accuracy: 0.5223\n",
            "Epoch 74/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3927 - accuracy: 0.8587\n",
            "Epoch 00074: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8472 - val_loss: 0.8791 - val_accuracy: 0.5263\n",
            "Epoch 75/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4006 - accuracy: 0.8504\n",
            "Epoch 00075: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8502 - val_loss: 0.8908 - val_accuracy: 0.5304\n",
            "Epoch 76/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4054 - accuracy: 0.8414\n",
            "Epoch 00076: val_accuracy did not improve from 0.55061\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8451 - val_loss: 0.9027 - val_accuracy: 0.5101\n",
            "Epoch 77/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.3952 - accuracy: 0.8570\n",
            "Epoch 00077: val_accuracy improved from 0.55061 to 0.56275, saving model to 3_weights-improvement-77-0.56.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8563 - val_loss: 0.8660 - val_accuracy: 0.5628\n",
            "Epoch 78/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.3962 - accuracy: 0.8438\n",
            "Epoch 00078: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8441 - val_loss: 0.8707 - val_accuracy: 0.5547\n",
            "Epoch 79/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3756 - accuracy: 0.8739\n",
            "Epoch 00079: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8664 - val_loss: 0.9053 - val_accuracy: 0.5223\n",
            "Epoch 80/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3685 - accuracy: 0.8672\n",
            "Epoch 00080: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8674 - val_loss: 0.9185 - val_accuracy: 0.5304\n",
            "Epoch 81/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3702 - accuracy: 0.8717\n",
            "Epoch 00081: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8745 - val_loss: 0.9097 - val_accuracy: 0.5223\n",
            "Epoch 82/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.3835 - accuracy: 0.8510\n",
            "Epoch 00082: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8583 - val_loss: 0.9320 - val_accuracy: 0.5263\n",
            "Epoch 83/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.3621 - accuracy: 0.8618\n",
            "Epoch 00083: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8664 - val_loss: 0.9080 - val_accuracy: 0.5547\n",
            "Epoch 84/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3464 - accuracy: 0.8862\n",
            "Epoch 00084: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8877 - val_loss: 0.9266 - val_accuracy: 0.5425\n",
            "Epoch 85/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3359 - accuracy: 0.8694\n",
            "Epoch 00085: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8664 - val_loss: 0.9869 - val_accuracy: 0.4980\n",
            "Epoch 86/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3287 - accuracy: 0.8850\n",
            "Epoch 00086: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8866 - val_loss: 0.9537 - val_accuracy: 0.5385\n",
            "Epoch 87/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.3289 - accuracy: 0.8895\n",
            "Epoch 00087: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8897 - val_loss: 0.9497 - val_accuracy: 0.5425\n",
            "Epoch 88/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.3204 - accuracy: 0.9014\n",
            "Epoch 00088: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8947 - val_loss: 0.9740 - val_accuracy: 0.5344\n",
            "Epoch 89/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3117 - accuracy: 0.8988\n",
            "Epoch 00089: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8998 - val_loss: 0.9766 - val_accuracy: 0.5425\n",
            "Epoch 90/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.3390 - accuracy: 0.8692\n",
            "Epoch 00090: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8684 - val_loss: 0.9943 - val_accuracy: 0.5344\n",
            "Epoch 91/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.3055 - accuracy: 0.8918\n",
            "Epoch 00091: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8947 - val_loss: 0.9909 - val_accuracy: 0.5385\n",
            "Epoch 92/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.2976 - accuracy: 0.8984\n",
            "Epoch 00092: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.9008 - val_loss: 1.0160 - val_accuracy: 0.5263\n",
            "Epoch 93/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.2988 - accuracy: 0.8981\n",
            "Epoch 00093: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9038 - val_loss: 1.0054 - val_accuracy: 0.5425\n",
            "Epoch 94/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.2783 - accuracy: 0.9243\n",
            "Epoch 00094: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.9211 - val_loss: 1.0107 - val_accuracy: 0.5466\n",
            "Epoch 95/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.2849 - accuracy: 0.9074\n",
            "Epoch 00095: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.9089 - val_loss: 1.0320 - val_accuracy: 0.5344\n",
            "Epoch 96/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.2584 - accuracy: 0.9201\n",
            "Epoch 00096: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9221 - val_loss: 1.0201 - val_accuracy: 0.5385\n",
            "Epoch 97/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.2732 - accuracy: 0.9097\n",
            "Epoch 00097: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.9109 - val_loss: 1.0370 - val_accuracy: 0.5385\n",
            "Epoch 98/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.2658 - accuracy: 0.9144\n",
            "Epoch 00098: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.9180 - val_loss: 1.0688 - val_accuracy: 0.5304\n",
            "Epoch 99/100\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.2678 - accuracy: 0.9086\n",
            "Epoch 00099: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.9099 - val_loss: 1.0399 - val_accuracy: 0.5425\n",
            "Epoch 100/100\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.2576 - accuracy: 0.9308\n",
            "Epoch 00100: val_accuracy did not improve from 0.56275\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9332 - val_loss: 1.0735 - val_accuracy: 0.5385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl_AVfLdsccM",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model against the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkkEuo_UQYXv",
        "colab_type": "text"
      },
      "source": [
        "Model #4 Architecture:\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\", input_dim=252),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])  \n",
        "\n",
        "* Epoch - 37\n",
        "* Training Accuracy - 0.7325\n",
        "* Validation Accuracy - 0.54656"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxF4VFpDQXa1",
        "colab_type": "code",
        "outputId": "b078c7bd-3311-4323-a5c4-69475bb874d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 4\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = True\n",
        "\n",
        "model_4, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_4.fit(x_train,y_train, \n",
        "                  epochs=epoch, \n",
        "                  validation_data = (x_val,y_val),\n",
        "                  callbacks=[callback_list])\n",
        "\n",
        "# review the learning rate performance\n",
        "chart_acc_loss(history)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 65,665\n",
            "Trainable params: 65,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.7005 - accuracy: 0.4844\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.52227, saving model to 4_weights-improvement-01-0.52.hdf5\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.4970 - val_loss: 0.6959 - val_accuracy: 0.5223\n",
            "Epoch 2/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6907 - accuracy: 0.5412\n",
            "Epoch 00002: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5395 - val_loss: 0.6951 - val_accuracy: 0.5223\n",
            "Epoch 3/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6863 - accuracy: 0.5482\n",
            "Epoch 00003: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.5506 - val_loss: 0.6957 - val_accuracy: 0.4980\n",
            "Epoch 4/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6878 - accuracy: 0.5475\n",
            "Epoch 00004: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5577 - val_loss: 0.6946 - val_accuracy: 0.5061\n",
            "Epoch 5/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6895 - accuracy: 0.5352\n",
            "Epoch 00005: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5344 - val_loss: 0.6945 - val_accuracy: 0.4980\n",
            "Epoch 6/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6802 - accuracy: 0.5913\n",
            "Epoch 00006: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5870 - val_loss: 0.6965 - val_accuracy: 0.5223\n",
            "Epoch 7/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6836 - accuracy: 0.5703\n",
            "Epoch 00007: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5810 - val_loss: 0.6965 - val_accuracy: 0.5182\n",
            "Epoch 8/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6822 - accuracy: 0.5450\n",
            "Epoch 00008: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.5455 - val_loss: 0.6977 - val_accuracy: 0.5061\n",
            "Epoch 9/100\n",
            "20/31 [==================>...........] - ETA: 0s - loss: 0.6778 - accuracy: 0.5750\n",
            "Epoch 00009: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.5577 - val_loss: 0.6940 - val_accuracy: 0.5142\n",
            "Epoch 10/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6761 - accuracy: 0.5913\n",
            "Epoch 00010: val_accuracy did not improve from 0.52227\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5931 - val_loss: 0.6963 - val_accuracy: 0.5101\n",
            "Epoch 11/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6738 - accuracy: 0.5938\n",
            "Epoch 00011: val_accuracy improved from 0.52227 to 0.53036, saving model to 4_weights-improvement-11-0.53.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5881 - val_loss: 0.6973 - val_accuracy: 0.5304\n",
            "Epoch 12/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6711 - accuracy: 0.6062\n",
            "Epoch 00012: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.6012 - val_loss: 0.6928 - val_accuracy: 0.5020\n",
            "Epoch 13/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6703 - accuracy: 0.6062\n",
            "Epoch 00013: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5992 - val_loss: 0.6951 - val_accuracy: 0.5101\n",
            "Epoch 14/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6664 - accuracy: 0.6046\n",
            "Epoch 00014: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.6113 - val_loss: 0.6995 - val_accuracy: 0.5263\n",
            "Epoch 15/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6577 - accuracy: 0.6338\n",
            "Epoch 00015: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6285 - val_loss: 0.7045 - val_accuracy: 0.5142\n",
            "Epoch 16/100\n",
            "22/31 [====================>.........] - ETA: 0s - loss: 0.6653 - accuracy: 0.6122\n",
            "Epoch 00016: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6316 - val_loss: 0.6955 - val_accuracy: 0.5142\n",
            "Epoch 17/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6603 - accuracy: 0.6250\n",
            "Epoch 00017: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6215 - val_loss: 0.6955 - val_accuracy: 0.5061\n",
            "Epoch 18/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6540 - accuracy: 0.6341\n",
            "Epoch 00018: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6306 - val_loss: 0.6985 - val_accuracy: 0.5101\n",
            "Epoch 19/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6520 - accuracy: 0.6370\n",
            "Epoch 00019: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6478 - val_loss: 0.6996 - val_accuracy: 0.5061\n",
            "Epoch 20/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6553 - accuracy: 0.6178\n",
            "Epoch 00020: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6225 - val_loss: 0.7035 - val_accuracy: 0.5223\n",
            "Epoch 21/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.6462 - accuracy: 0.6430\n",
            "Epoch 00021: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6447 - val_loss: 0.6987 - val_accuracy: 0.5061\n",
            "Epoch 22/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6411 - accuracy: 0.6625\n",
            "Epoch 00022: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6640 - val_loss: 0.7067 - val_accuracy: 0.5182\n",
            "Epoch 23/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6359 - accuracy: 0.6650\n",
            "Epoch 00023: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6579 - val_loss: 0.6982 - val_accuracy: 0.5142\n",
            "Epoch 24/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6279 - accuracy: 0.6850\n",
            "Epoch 00024: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6771 - val_loss: 0.7062 - val_accuracy: 0.5223\n",
            "Epoch 25/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6341 - accuracy: 0.6637\n",
            "Epoch 00025: val_accuracy did not improve from 0.53036\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6731 - val_loss: 0.7065 - val_accuracy: 0.5263\n",
            "Epoch 26/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6185 - accuracy: 0.6914\n",
            "Epoch 00026: val_accuracy improved from 0.53036 to 0.53846, saving model to 4_weights-improvement-26-0.54.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6883 - val_loss: 0.7145 - val_accuracy: 0.5385\n",
            "Epoch 27/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.6180 - accuracy: 0.6943\n",
            "Epoch 00027: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6771 - val_loss: 0.7071 - val_accuracy: 0.5142\n",
            "Epoch 28/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6156 - accuracy: 0.7075\n",
            "Epoch 00028: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6994 - val_loss: 0.7052 - val_accuracy: 0.5101\n",
            "Epoch 29/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6138 - accuracy: 0.6680\n",
            "Epoch 00029: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6791 - val_loss: 0.7097 - val_accuracy: 0.5223\n",
            "Epoch 30/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.6069 - accuracy: 0.6914\n",
            "Epoch 00030: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6893 - val_loss: 0.7151 - val_accuracy: 0.5223\n",
            "Epoch 31/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.6049 - accuracy: 0.7163\n",
            "Epoch 00031: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.7105 - val_loss: 0.7149 - val_accuracy: 0.5304\n",
            "Epoch 32/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5936 - accuracy: 0.7357\n",
            "Epoch 00032: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7196 - val_loss: 0.7234 - val_accuracy: 0.5223\n",
            "Epoch 33/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5872 - accuracy: 0.7237\n",
            "Epoch 00033: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7176 - val_loss: 0.7236 - val_accuracy: 0.5263\n",
            "Epoch 34/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5967 - accuracy: 0.7005\n",
            "Epoch 00034: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6974 - val_loss: 0.7342 - val_accuracy: 0.5304\n",
            "Epoch 35/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5880 - accuracy: 0.7135\n",
            "Epoch 00035: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7237 - val_loss: 0.7277 - val_accuracy: 0.5304\n",
            "Epoch 36/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.5821 - accuracy: 0.7091\n",
            "Epoch 00036: val_accuracy did not improve from 0.53846\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7136 - val_loss: 0.7281 - val_accuracy: 0.5385\n",
            "Epoch 37/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.5782 - accuracy: 0.7248\n",
            "Epoch 00037: val_accuracy improved from 0.53846 to 0.54656, saving model to 4_weights-improvement-37-0.55.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7348 - val_loss: 0.7287 - val_accuracy: 0.5466\n",
            "Epoch 38/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5625 - accuracy: 0.7582\n",
            "Epoch 00038: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7449 - val_loss: 0.7312 - val_accuracy: 0.5385\n",
            "Epoch 39/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5507 - accuracy: 0.7552\n",
            "Epoch 00039: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7490 - val_loss: 0.7323 - val_accuracy: 0.5223\n",
            "Epoch 40/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5489 - accuracy: 0.7351\n",
            "Epoch 00040: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7419 - val_loss: 0.7423 - val_accuracy: 0.5425\n",
            "Epoch 41/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5409 - accuracy: 0.7387\n",
            "Epoch 00041: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7439 - val_loss: 0.7556 - val_accuracy: 0.5304\n",
            "Epoch 42/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5425 - accuracy: 0.7437\n",
            "Epoch 00042: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7490 - val_loss: 0.7551 - val_accuracy: 0.5425\n",
            "Epoch 43/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5432 - accuracy: 0.7500\n",
            "Epoch 00043: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7561 - val_loss: 0.7689 - val_accuracy: 0.5182\n",
            "Epoch 44/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5297 - accuracy: 0.7617\n",
            "Epoch 00044: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7591 - val_loss: 0.7747 - val_accuracy: 0.5142\n",
            "Epoch 45/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5104 - accuracy: 0.7826\n",
            "Epoch 00045: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7753 - val_loss: 0.7908 - val_accuracy: 0.4980\n",
            "Epoch 46/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5195 - accuracy: 0.7750\n",
            "Epoch 00046: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7753 - val_loss: 0.7908 - val_accuracy: 0.4939\n",
            "Epoch 47/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.5136 - accuracy: 0.7622\n",
            "Epoch 00047: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7642 - val_loss: 0.7738 - val_accuracy: 0.5344\n",
            "Epoch 48/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.5018 - accuracy: 0.7708\n",
            "Epoch 00048: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7662 - val_loss: 0.7893 - val_accuracy: 0.5304\n",
            "Epoch 49/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.5020 - accuracy: 0.7638\n",
            "Epoch 00049: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7672 - val_loss: 0.8005 - val_accuracy: 0.5020\n",
            "Epoch 50/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4807 - accuracy: 0.7880\n",
            "Epoch 00050: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7966 - val_loss: 0.7997 - val_accuracy: 0.5425\n",
            "Epoch 51/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4610 - accuracy: 0.8250\n",
            "Epoch 00051: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8209 - val_loss: 0.8140 - val_accuracy: 0.5101\n",
            "Epoch 52/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4823 - accuracy: 0.7887\n",
            "Epoch 00052: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7874 - val_loss: 0.8376 - val_accuracy: 0.4899\n",
            "Epoch 53/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4685 - accuracy: 0.8062\n",
            "Epoch 00053: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8087 - val_loss: 0.8272 - val_accuracy: 0.5142\n",
            "Epoch 54/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.4495 - accuracy: 0.8138\n",
            "Epoch 00054: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8117 - val_loss: 0.8221 - val_accuracy: 0.5182\n",
            "Epoch 55/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.4387 - accuracy: 0.8268\n",
            "Epoch 00055: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8279 - val_loss: 0.8339 - val_accuracy: 0.5263\n",
            "Epoch 56/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4320 - accuracy: 0.8478\n",
            "Epoch 00056: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8391 - val_loss: 0.8674 - val_accuracy: 0.5061\n",
            "Epoch 57/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4265 - accuracy: 0.8388\n",
            "Epoch 00057: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8310 - val_loss: 0.8570 - val_accuracy: 0.5263\n",
            "Epoch 58/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4206 - accuracy: 0.8363\n",
            "Epoch 00058: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8300 - val_loss: 0.8690 - val_accuracy: 0.5182\n",
            "Epoch 59/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4177 - accuracy: 0.8329\n",
            "Epoch 00059: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8320 - val_loss: 0.9005 - val_accuracy: 0.5020\n",
            "Epoch 60/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3991 - accuracy: 0.8487\n",
            "Epoch 00060: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8381 - val_loss: 0.8839 - val_accuracy: 0.5263\n",
            "Epoch 61/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3984 - accuracy: 0.8300\n",
            "Epoch 00061: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8289 - val_loss: 0.9293 - val_accuracy: 0.4980\n",
            "Epoch 62/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.4029 - accuracy: 0.8398\n",
            "Epoch 00062: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8391 - val_loss: 0.9024 - val_accuracy: 0.4939\n",
            "Epoch 63/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.4003 - accuracy: 0.8356\n",
            "Epoch 00063: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8482 - val_loss: 0.9051 - val_accuracy: 0.4858\n",
            "Epoch 64/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.3762 - accuracy: 0.8503\n",
            "Epoch 00064: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8573 - val_loss: 0.9441 - val_accuracy: 0.4939\n",
            "Epoch 65/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3777 - accuracy: 0.8612\n",
            "Epoch 00065: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8623 - val_loss: 0.9317 - val_accuracy: 0.4980\n",
            "Epoch 66/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3530 - accuracy: 0.8712\n",
            "Epoch 00066: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8745 - val_loss: 0.9280 - val_accuracy: 0.5142\n",
            "Epoch 67/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3498 - accuracy: 0.8875\n",
            "Epoch 00067: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8816 - val_loss: 0.9449 - val_accuracy: 0.5142\n",
            "Epoch 68/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.3492 - accuracy: 0.8815\n",
            "Epoch 00068: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8816 - val_loss: 0.9554 - val_accuracy: 0.4939\n",
            "Epoch 69/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3359 - accuracy: 0.8700\n",
            "Epoch 00069: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8623 - val_loss: 0.9545 - val_accuracy: 0.5142\n",
            "Epoch 70/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.3152 - accuracy: 0.8981\n",
            "Epoch 00070: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.9028 - val_loss: 1.0277 - val_accuracy: 0.4980\n",
            "Epoch 71/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.3168 - accuracy: 0.8893\n",
            "Epoch 00071: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8907 - val_loss: 0.9851 - val_accuracy: 0.5182\n",
            "Epoch 72/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.3140 - accuracy: 0.8997\n",
            "Epoch 00072: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8968 - val_loss: 1.0072 - val_accuracy: 0.4980\n",
            "Epoch 73/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3153 - accuracy: 0.8813\n",
            "Epoch 00073: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8826 - val_loss: 1.0179 - val_accuracy: 0.4980\n",
            "Epoch 74/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3113 - accuracy: 0.8888\n",
            "Epoch 00074: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8927 - val_loss: 1.0285 - val_accuracy: 0.5020\n",
            "Epoch 75/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2944 - accuracy: 0.9000\n",
            "Epoch 00075: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8978 - val_loss: 1.0475 - val_accuracy: 0.4899\n",
            "Epoch 76/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.3037 - accuracy: 0.9025\n",
            "Epoch 00076: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.9038 - val_loss: 1.0517 - val_accuracy: 0.4939\n",
            "Epoch 77/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2903 - accuracy: 0.9025\n",
            "Epoch 00077: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.9008 - val_loss: 1.0489 - val_accuracy: 0.5061\n",
            "Epoch 78/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2822 - accuracy: 0.8971\n",
            "Epoch 00078: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8988 - val_loss: 1.0576 - val_accuracy: 0.5101\n",
            "Epoch 79/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2710 - accuracy: 0.9100\n",
            "Epoch 00079: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.9130 - val_loss: 1.0696 - val_accuracy: 0.5142\n",
            "Epoch 80/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.2817 - accuracy: 0.9076\n",
            "Epoch 00080: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9069 - val_loss: 1.0973 - val_accuracy: 0.4899\n",
            "Epoch 81/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2654 - accuracy: 0.9125\n",
            "Epoch 00081: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.9099 - val_loss: 1.0954 - val_accuracy: 0.4980\n",
            "Epoch 82/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2748 - accuracy: 0.9062\n",
            "Epoch 00082: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9079 - val_loss: 1.1016 - val_accuracy: 0.5101\n",
            "Epoch 83/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2580 - accuracy: 0.9180\n",
            "Epoch 00083: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.9221 - val_loss: 1.1047 - val_accuracy: 0.5061\n",
            "Epoch 84/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2492 - accuracy: 0.9237\n",
            "Epoch 00084: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9200 - val_loss: 1.1203 - val_accuracy: 0.5061\n",
            "Epoch 85/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2431 - accuracy: 0.9284\n",
            "Epoch 00085: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.9241 - val_loss: 1.1428 - val_accuracy: 0.5020\n",
            "Epoch 86/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2323 - accuracy: 0.9336\n",
            "Epoch 00086: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.9322 - val_loss: 1.1479 - val_accuracy: 0.5061\n",
            "Epoch 87/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2150 - accuracy: 0.9505\n",
            "Epoch 00087: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9453 - val_loss: 1.1680 - val_accuracy: 0.4980\n",
            "Epoch 88/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.2353 - accuracy: 0.9212\n",
            "Epoch 00088: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9190 - val_loss: 1.1793 - val_accuracy: 0.5061\n",
            "Epoch 89/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2092 - accuracy: 0.9414\n",
            "Epoch 00089: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9433 - val_loss: 1.1818 - val_accuracy: 0.4980\n",
            "Epoch 90/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2278 - accuracy: 0.9262\n",
            "Epoch 00090: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9271 - val_loss: 1.1952 - val_accuracy: 0.5020\n",
            "Epoch 91/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2067 - accuracy: 0.9401\n",
            "Epoch 00091: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.2051 - accuracy: 0.9393 - val_loss: 1.2169 - val_accuracy: 0.5101\n",
            "Epoch 92/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.2089 - accuracy: 0.9325\n",
            "Epoch 00092: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9362 - val_loss: 1.2411 - val_accuracy: 0.4939\n",
            "Epoch 93/100\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 0.2115 - accuracy: 0.9443\n",
            "Epoch 00093: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9393 - val_loss: 1.2603 - val_accuracy: 0.4899\n",
            "Epoch 94/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.1997 - accuracy: 0.9483\n",
            "Epoch 00094: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9494 - val_loss: 1.2475 - val_accuracy: 0.5061\n",
            "Epoch 95/100\n",
            "24/31 [======================>.......] - ETA: 0s - loss: 0.2028 - accuracy: 0.9414\n",
            "Epoch 00095: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9423 - val_loss: 1.2570 - val_accuracy: 0.5101\n",
            "Epoch 96/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1865 - accuracy: 0.9450\n",
            "Epoch 00096: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9464 - val_loss: 1.2670 - val_accuracy: 0.5101\n",
            "Epoch 97/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1836 - accuracy: 0.9488\n",
            "Epoch 00097: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9494 - val_loss: 1.2802 - val_accuracy: 0.5020\n",
            "Epoch 98/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1912 - accuracy: 0.9388\n",
            "Epoch 00098: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9423 - val_loss: 1.3232 - val_accuracy: 0.4777\n",
            "Epoch 99/100\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.1905 - accuracy: 0.9351\n",
            "Epoch 00099: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9383 - val_loss: 1.2884 - val_accuracy: 0.5142\n",
            "Epoch 100/100\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.1872 - accuracy: 0.9375\n",
            "Epoch 00100: val_accuracy did not improve from 0.54656\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9322 - val_loss: 1.3040 - val_accuracy: 0.5101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrDXo6fUUAGs",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate against the Test set\n",
        "\n",
        "The model is evaluated against the test set to determine if the models can generalize well to new data.\n",
        "\n",
        "In order to do this, the weights saved for each model are loaded into a new model instance, which would be similar to how a model would be implemented in \"production\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO0GvDe4QoW7",
        "colab_type": "code",
        "outputId": "05a5ff06-4fd9-4877-f566-f2dae8a4ba0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# define the model parameters\n",
        "model_number = 2\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "# create a new model instance\n",
        "model_2, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "# load weights\n",
        "model_2.load_weights('/content/2_weights-improvement-19-0.56.hdf5')\n",
        "\n",
        "# verify the model performance by verifiying the validation accuracy\n",
        "model_2.evaluate(x_val,y_val)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.5628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6969975829124451, 0.5627530217170715]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp7RvZ81M_X-",
        "colab_type": "code",
        "outputId": "90d1e11b-25ef-4615-d862-5081b67a560b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Evaluate the test set performance\n",
        "model_2.evaluate(x_test,y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.4634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7046247124671936, 0.46341463923454285]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gfR0H10T_JT",
        "colab_type": "code",
        "outputId": "ff833b55-91de-4321-b3cd-f7257740db7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# define the model parameters\n",
        "model_number = 3\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "# create a new model instance\n",
        "model_3, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "# load weights\n",
        "model_3.load_weights('/content/3_weights-improvement-77-0.56.hdf5')\n",
        "\n",
        "# verify the model performance by verifiying the validation accuracy\n",
        "model_3.evaluate(x_val,y_val)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 49,025\n",
            "Trainable params: 49,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.8660 - accuracy: 0.5628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8659567832946777, 0.5627530217170715]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUTweAxuNctd",
        "colab_type": "code",
        "outputId": "6345c2f6-1d00-4516-bcb4-573e7f9ff87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Evaluate the test set performance\n",
        "model_3.evaluate(x_test,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.4715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9001762866973877, 0.47154471278190613]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAVQAzqzUG-Q",
        "colab_type": "code",
        "outputId": "aef14c98-9b2a-4f45-808d-b03360ff9a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# define the model parameters\n",
        "model_number = 4\n",
        "epoch = 100\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "# create a new model instance\n",
        "model_4, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "# load weights\n",
        "model_4.load_weights('/content/4_weights-improvement-37-0.55.hdf5')\n",
        "\n",
        "# verify the model performance by verifiying the validation accuracy\n",
        "model_4.evaluate(x_val,y_val)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 65,665\n",
            "Trainable params: 65,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.5466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7286739349365234, 0.546558678150177]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibqeza_4OevY",
        "colab_type": "code",
        "outputId": "fbd6a6c1-e11b-4681-928e-20640359bd05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Evaluate the test set performance\n",
        "model_4.evaluate(x_test,y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.4634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7380712032318115, 0.46341463923454285]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc1IByKTKVnF",
        "colab_type": "text"
      },
      "source": [
        "In summary, there are the accuracy for the three models:\n",
        "\n",
        "Model #2\n",
        "* Training Accuracy - 0.5898\n",
        "* Validation Accuracy - 0.56275\n",
        "* Testing Accuracy - 0.4634\n",
        "\n",
        "Model #3\n",
        "* Training Accuracy - 0.8570\n",
        "* Validation Accuracy - 0.56275\n",
        "* Testing Accuracy - 0.4715\n",
        "\n",
        "Model #4\n",
        "* Training Accuracy - 0.7325\n",
        "* Validation Accuracy - 0.54656\n",
        "* Testing Accuracy - 0.4634"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYr5kjrZF_V1",
        "colab_type": "text"
      },
      "source": [
        "### Train and Evaluate a Rolling 4-Year Models\n",
        "\n",
        "The rolling 4-year models were evaluated using a training dataset of 2015 to 2018 and testing against 2019 dataset.\n",
        "\n",
        "A modified load_data function is to adjust the datasets to training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUP0m8sVB3-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_rolling(start_year, target_year):\n",
        "\n",
        "  data = pd.read_csv('https://raw.githubusercontent.com/dkim319/NFL_Predictive_Model_NN/master/Data.csv')\n",
        "\n",
        "  data = data[data['season'] >= start_year]\n",
        "\n",
        "  # replace any null values with 0\n",
        "  data = data.fillna(0)\n",
        "\n",
        "  # use one-hot coding to replace the favorite and underdog categorical variables\n",
        "  fav_team = pd.get_dummies(data['favorite'])\n",
        "  und_team = pd.get_dummies(data['underdog'])\n",
        "\n",
        "  # use a prefix to distinguish the two categorical variables\n",
        "  fav_team = fav_team.add_prefix('fav_')\n",
        "  und_team = und_team.add_prefix('und_')\n",
        "\n",
        "  # remove the original fields\n",
        "  data = data.drop('favorite', axis = 1)\n",
        "  data = data.drop('underdog', axis = 1)\n",
        "\n",
        "  # add the one-hot coded fields\n",
        "  data = pd.concat([data, fav_team], axis = 1)\n",
        "  data = pd.concat([data, und_team], axis = 1)\n",
        "\n",
        "  #print data.head(5)\n",
        "  #print(data.describe())\n",
        "\n",
        "  # split the dataset into training and testing datasets\n",
        "  data_train = data[data['season'] <= target_year-1]\n",
        "  data_train.reset_index()\n",
        "  data_test = data[data['season'] == target_year]\n",
        "  data_test.reset_index()\n",
        "\n",
        "  # split training and testing datasets into features and target \n",
        "  features_train = data_train.drop('spreadflag', axis = 1)\n",
        "  target_train = data_train['spreadflag']\n",
        "\n",
        "  features_test = data_test.drop('spreadflag', axis = 1)\n",
        "  target_test = data_test['spreadflag']\n",
        "\n",
        "  return data_train, data_test, features_train, target_train, features_test, target_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESVr6ldnJsn-",
        "colab_type": "text"
      },
      "source": [
        "The data is loaded using the new function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_j1BV4jB7xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_year = 2015\n",
        "test_year = 2019\n",
        "\n",
        "data_train, data_test, features_train, target_train, features_test, target_test = load_data_rolling(start_year, test_year)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(features_train)\n",
        "\n",
        "x_train = scaler.transform(features_train).astype('float32')\n",
        "x_test = scaler.transform(features_test).astype('float32')\n",
        "\n",
        "y_train = target_train.to_numpy().astype('float32')\n",
        "y_test = target_test.to_numpy().astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXBsOti0bD7x",
        "colab_type": "code",
        "outputId": "2d29f114-dc67-4058-cb44-f108d7ac3161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_number = 2\n",
        "epoch = 19\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "model_2_rolling, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_2_rolling.fit(x_train,y_train, \n",
        "                  epochs=epoch)\n",
        "\n",
        "# Evaluate the test set performance\n",
        "print('Model' + str(model_number) + ' - 2019 accuracy')\n",
        "model_2_rolling.evaluate(x_test,y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.5041\n",
            "Epoch 2/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4980\n",
            "Epoch 3/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5244\n",
            "Epoch 4/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5122\n",
            "Epoch 5/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5244\n",
            "Epoch 6/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5295\n",
            "Epoch 7/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5274\n",
            "Epoch 8/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5457\n",
            "Epoch 9/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5589\n",
            "Epoch 10/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5762\n",
            "Epoch 11/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5346\n",
            "Epoch 12/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5711\n",
            "Epoch 13/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5569\n",
            "Epoch 14/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5630\n",
            "Epoch 15/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5650\n",
            "Epoch 16/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5803\n",
            "Epoch 17/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5976\n",
            "Epoch 18/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5793\n",
            "Epoch 19/19\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5620\n",
            "Model2 - 2019 accuracy\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7045849561691284, 0.5203251838684082]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIstkQhGETMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff19c989-b711-47f4-9a3e-b837d31bcbee"
      },
      "source": [
        "model_number = 3\n",
        "epoch = 77\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "model_3_rolling, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_3_rolling.fit(x_train,y_train, \n",
        "                  epochs=epoch)\n",
        "\n",
        "# Evaluate the test set performance\n",
        "print('Model' + str(model_number) + ' - 2019 accuracy')\n",
        "model_3_rolling.evaluate(x_test,y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 49,025\n",
            "Trainable params: 49,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5112\n",
            "Epoch 2/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.4888\n",
            "Epoch 3/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5000\n",
            "Epoch 4/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5213\n",
            "Epoch 5/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5142\n",
            "Epoch 6/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5539\n",
            "Epoch 7/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5366\n",
            "Epoch 8/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5376\n",
            "Epoch 9/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5264\n",
            "Epoch 10/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5691\n",
            "Epoch 11/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5732\n",
            "Epoch 12/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5528\n",
            "Epoch 13/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5691\n",
            "Epoch 14/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.5813\n",
            "Epoch 15/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5783\n",
            "Epoch 16/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.5935\n",
            "Epoch 17/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5935\n",
            "Epoch 18/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5945\n",
            "Epoch 19/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.5955\n",
            "Epoch 20/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6077\n",
            "Epoch 21/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.6026\n",
            "Epoch 22/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6402\n",
            "Epoch 23/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6209\n",
            "Epoch 24/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6230\n",
            "Epoch 25/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6291\n",
            "Epoch 26/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6433\n",
            "Epoch 27/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6159\n",
            "Epoch 28/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6362\n",
            "Epoch 29/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6270\n",
            "Epoch 30/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6341\n",
            "Epoch 31/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6484\n",
            "Epoch 32/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6484\n",
            "Epoch 33/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6616\n",
            "Epoch 34/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6819\n",
            "Epoch 35/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6829\n",
            "Epoch 36/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6687\n",
            "Epoch 37/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6900\n",
            "Epoch 38/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6839\n",
            "Epoch 39/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6829\n",
            "Epoch 40/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6870\n",
            "Epoch 41/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.6687\n",
            "Epoch 42/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7093\n",
            "Epoch 43/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7175\n",
            "Epoch 44/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7236\n",
            "Epoch 45/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6900\n",
            "Epoch 46/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7043\n",
            "Epoch 47/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7134\n",
            "Epoch 48/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7297\n",
            "Epoch 49/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7256\n",
            "Epoch 50/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7144\n",
            "Epoch 51/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7459\n",
            "Epoch 52/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7459\n",
            "Epoch 53/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7490\n",
            "Epoch 54/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7317\n",
            "Epoch 55/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7480\n",
            "Epoch 56/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7652\n",
            "Epoch 57/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7480\n",
            "Epoch 58/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7612\n",
            "Epoch 59/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7734\n",
            "Epoch 60/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7652\n",
            "Epoch 61/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8028\n",
            "Epoch 62/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7856\n",
            "Epoch 63/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7927\n",
            "Epoch 64/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7886\n",
            "Epoch 65/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7846\n",
            "Epoch 66/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7927\n",
            "Epoch 67/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7967\n",
            "Epoch 68/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8120\n",
            "Epoch 69/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8008\n",
            "Epoch 70/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8222\n",
            "Epoch 71/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8191\n",
            "Epoch 72/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8404\n",
            "Epoch 73/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8343\n",
            "Epoch 74/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8252\n",
            "Epoch 75/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8384\n",
            "Epoch 76/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8364\n",
            "Epoch 77/77\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8496\n",
            "Model3 - 2019 accuracy\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.8708 - accuracy: 0.4959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8707537651062012, 0.49593496322631836]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XnNOTw0C8i9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8963110-41da-488b-d0c1-fb84954df069"
      },
      "source": [
        "model_number = 4\n",
        "epoch = 37\n",
        "learning_rate = 0.0001\n",
        "lr_cb = False\n",
        "cp_cb = False\n",
        "\n",
        "model_4_rolling, callback_list = define_model(model_number, epoch, learning_rate, lr_cb, cp_cb)\n",
        "\n",
        "history = model_4_rolling.fit(x_train,y_train, \n",
        "                  epochs=epoch)\n",
        "\n",
        "# Evaluate the test set performance\n",
        "print('Model' + str(model_number) + ' - 2019 accuracy')\n",
        "model_3_rolling.evaluate(x_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               32384     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 65,665\n",
            "Trainable params: 65,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.4919\n",
            "Epoch 2/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5061\n",
            "Epoch 3/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4980\n",
            "Epoch 4/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5407\n",
            "Epoch 5/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5285\n",
            "Epoch 6/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5335\n",
            "Epoch 7/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5620\n",
            "Epoch 8/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5722\n",
            "Epoch 9/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5803\n",
            "Epoch 10/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6037\n",
            "Epoch 11/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5793\n",
            "Epoch 12/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.6077\n",
            "Epoch 13/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5864\n",
            "Epoch 14/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6321\n",
            "Epoch 15/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6026\n",
            "Epoch 16/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6108\n",
            "Epoch 17/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6209\n",
            "Epoch 18/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6372\n",
            "Epoch 19/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6311\n",
            "Epoch 20/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6402\n",
            "Epoch 21/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6514\n",
            "Epoch 22/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6514\n",
            "Epoch 23/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6585\n",
            "Epoch 24/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6575\n",
            "Epoch 25/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6596\n",
            "Epoch 26/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6667\n",
            "Epoch 27/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6890\n",
            "Epoch 28/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6362\n",
            "Epoch 29/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6758\n",
            "Epoch 30/37\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6850\n",
            "Epoch 31/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6880\n",
            "Epoch 32/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7205\n",
            "Epoch 33/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.7022\n",
            "Epoch 34/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7114\n",
            "Epoch 35/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7124\n",
            "Epoch 36/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7043\n",
            "Epoch 37/37\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7378\n",
            "Model4 - 2019 accuracy\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.8708 - accuracy: 0.4959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8707537651062012, 0.49593496322631836]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9kjGMoyLyBZ",
        "colab_type": "text"
      },
      "source": [
        "In summary, there are the accuracy for the three models:\n",
        "\n",
        "Model #2\n",
        "\n",
        "* Training Accuracy - 0.5620\n",
        "* Testing Accuracy - 0.5203\n",
        "\n",
        "Model #3\n",
        "\n",
        "* Training Accuracy - 0.8496\n",
        "* Testing Accuracy - 0.4959\n",
        "\n",
        "Model #4\n",
        "\n",
        "* Training Accuracy - 0.7378\n",
        "* Testing Accuracy - 0.4959\n",
        "\n",
        "## Summary\n",
        "\n",
        "\n",
        "The first set of models performed poorly against the test dataset.  All three models performed worse than the baseline.  The second set of models using a rolling 4-year training dataset also performed similarly against the test dataset with the exception of the model #2, which had 52.03%.\n",
        "\n",
        "This type of result was not surprising since the dyanmic nature of the NFL data where the relationship between the feature and target variables will change from season to season.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "The next steps is to monitor the models using the 7-year and 4-year rolling training datasets to see how well they fare against the next NFL season."
      ]
    }
  ]
}